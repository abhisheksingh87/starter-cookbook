[{"uri":"/recipes-non-reactive/configure-oracle/","title":"Configure Oracle","tags":["persistence","hikari","database connection pool","anti patterns"],"description":"","content":"Context This is the second recipe in the series, for developing a modern cloud ready microservice using the greenfield-app-starter.\nThis recipe deals with configuring persistence in the microservice.\nThe HikariDatasource bean with preconfigured connection pool is used to fulfill persistence needs in the microservice.\nPrerequisite  STEP 1: CREATE APPLICATION USING THE STARTER is completed.  Solution   Determine and record the following oracle database connection details\n   Property Details     jdbc url jdbc:oracle:thin:@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;:\u0026lt;schema\u0026gt; [thin] OR jdbc:oracle:oci:@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;:\u0026lt;schema\u0026gt; [oci]   driver classname oracle.jdbc.OracleDriver   schema database schema name   dialect Hibernate dialect based on the Oracle database version org.hibernate.dialect.Oracle12cDialect   username schema username   password schema password      Determine and record the database connection pool requirements for the new microservice\n   Property Suggested Values     maximumPoolSize 10   idlePoolSize 2   connectionTimeout 250ms   idleTimeout 800ms   maxLifetime 3000ms      Navigate to the \u0026lt;microservice\u0026gt; directory\n  Update the database connection and connection pool requirements in src/main/resources/application.yml\napplication:name:description:id:\u0026lt;wells fargo distributed-id\u0026gt;persistence:oracle:name:\u0026lt;user friendly database name\u0026gt;url:\u0026lt;jdbc url format\u0026gt;username:password:schema:dialect:\u0026lt;hibernate oracle dialect\u0026gt;connection-pool:maximumPoolSize:\u0026lt;less than 10\u0026gt;connectionTimeout:\u0026lt;in millisecs\u0026gt;idleTimeout:\u0026lt;in millisecs\u0026gt;maxLifetime:\u0026lt;in millisecs\u0026gt;  Validation   Open a command window in the \u0026lt;microservice-name\u0026gt; directory\n  Validate the new microservice can be built locally: gradlew bootJar\n  Validate the new microservice runs locally: gradlew bootRun\n  Verify microservice health and info in the browser\n  http://localhost:8080/actuator/info\n  http://localhost:8080/actuator/health\nthe datasource details and uptime status should be displayed in the browser.\n  http://localhost:8080/actuator/beans\nsearch for HikariDataSource in the browser.\n    Next Step Configure the Cache\nNotes and References  https://github.com/pbelathur/spring-boot-performance-analysis  Anti Patterns  Oversizing the maximumPoolSize Having too many idle connections Setting high maxLifetime  "},{"uri":"/common/create-app-using-starter/","title":"Create microservice using starter","tags":["starter","microservice","barebone microservice"],"description":"","content":"Context This is the first recipe in the series, for developing a modern cloud ready microservice using the greenfield-app-starter.\nUpon completion of this recipe you will have a working spring boot microservice with health, info and metrics endpoints enabled.\nPrerequisite  JDK 8 or greater IntelliJ or Eclipse IDE GIT client Access to greenfield-app-starter Github repo  Solution   Collect or record the following details for the new microservice\n   Property Description Example     lob line of business consumer   business-group business group within the lob lending   application-group application category or grouping loan   microservice-name camelCased name AutoLoanCalculator   microservice-version in major.minor.patch format; start with 0.1.0 0.1.0   description short phrase describing the purpose of the microservice consumer auto loan calculator for period less than 36 months   JDK-version Java 8 or above; one of 1.8, 1.11, 1.12, 1.13 or 1.14 1.12   project-group com.wellsfargo.\u0026lt;lob\u0026gt;.\u0026lt;business-group\u0026gt;.\u0026lt;application-group\u0026gt; com.wellsfargo.consumer.lending.loan      Clone the greenfield-app-starter from Gitlab repo git clone \u0026lt;repo url\u0026gt;\n  Rename folder: greenfield-app-starter to \u0026lt;microservice-name\u0026gt;\n(example: AutoLoanCalculator)\n  Update the microservice name in settings.gradle\nrootProject.name = \u0026#34;\u0026lt;microservice-name\u0026gt;\u0026#34; # EXAMPLE rootProject.name = \u0026#34;AutoLoanCalculator\u0026#34;   Update project details in build.gradle\ndescription = \u0026#34;\u0026lt;description\u0026gt;\u0026#34; group = \u0026#34;\u0026lt;project-group\u0026gt;\u0026#34; version = \u0026#34;\u0026lt;microservice-version\u0026gt;\u0026#34; sourceCompatibility = \u0026#34;\u0026lt;JDK-version\u0026gt;\u0026#34; # EXAMPLE description = \u0026#34;consumer auto loan calculator for period less than 36 months\u0026#34; group = \u0026#34;com.wellsfargo.consumer.lending.loan\u0026#34; version = \u0026#34;0.1.0\u0026#34; sourceCompatibility = \u0026#34;1.12\u0026#34;   Rename package from com.wellsfargo.cto.eai.starter to \u0026lt;project-group\u0026gt;\n(example: com.wellsfargo.consumer.lending.loan)\n  Rename main application classname from GreenfieldMicroservice to \u0026lt;microservice-name\u0026gt;\n(example: AutoLoanCalculator)\n  As an example, the barebone microservice will have the following:\n folder: AutoLoanCalculator containing  com.wellsfargo.consumer.lending.loan.AutoLoanCalculator.java src/main/resources/application.yml build.gradle settings.gradle      Create the codebase folder structure based on the\u0026lt;recipe\u0026gt; in Best Practices\n  Validation   Open a command window in the \u0026lt;microservice-name\u0026gt; directory\n  Validate the new microservice can be built locally: gradlew bootJar\n  Validate the new microservice runs locally: gradlew bootRun\n  Verify microservice health and info in the browser\n http://localhost:8080/actuator/health http://localhost:8080/actuator/info    Next Step Follow the Reactive or Non-Reactive recipes depending on your microservice needs.\nNotes and References "},{"uri":"/best-practices/custom-spring-validation/","title":"Custom Spring Bean Validation","tags":["practices","spring boot","microservice","custom spring bean validation"],"description":"A guide to use custom validation","content":"Context While implementing Spring REST endpoints for Spring boot applications, adding validations (inbuilt/custom) becomes inevitable. For most cases the inbuilt validators provided by JSR 380, also known as Bean Validation 2.0 framework would suffice. Some of the inbuilt validators provided are: @NotNull, @NotEmpty, @NotBlank, @Min, @Max, @Size to name a few. There are still instances where the validation need can’t be taken care of by the inbuilt validators provided by JSR 380 and in such cases we need to write custom validators which takes care of providing custom validation logic to the bean attributes.\nUse Case: Let’s assume a use case wherein we need to validate customer location details with custom validation of fields locationId, countryCode and postCode. These three fields should accept only numeric strings (ex: “123\u0026quot;)\n@Getter @Setter public class CustomerLocation { @NumericString(message = \u0026#34;locationId should be numeric\u0026#34;) private String locationId; @NotBlank(message = \u0026#34;city cannot not be empty\u0026#34;) private String city; @NumericString(message = \u0026#34;countryCode should be numeric\u0026#34;) private String countryCode; @NumericString(message = \u0026#34;postCode should be numeric\u0026#34;) private String postCode; } In the above example both inbuilt (@NotBlank) and custom (@NumericString) validators are being used. @NotBlank would ensure that the value passed to city attribute is not blank however @NumericString validator would ensure that the value passed to locationId, countryCode \u0026amp; postCode is a numeric string\nSetup: Add below dependency to build.gradle. The latest dependency can be checked here\n compile group: 'org.hibernate', name: 'hibernate-validator', version: '4.2.0.Final' If we\u0026rsquo;re using Spring Boot, then we can add only the spring-boot-starter-web, which will bring in the hibernate-validator dependency also.\nController: Lets see the REST endpoint which validates the incoming request:\n@RestController public class ValidatorController { @PostMapping(value=\u0026#34;/v1/validate\u0026#34;, produces = \u0026#34;application/json\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; validateCustomerLocation(@ValidCustomerLocation @RequestBody CustomerLocation customerLocation){ return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.ACCEPTED); } } Custom validators: ValidCustomerLocation is a custom validator annotation for which the constraints would be validated by CustomerLocationValidator class as shown below:\n@Target({ElementType.FIELD, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Constraint(validatedBy = {CustomerLocationValidator.class}) @Documented public @interface ValidCustomerLocation { String message() default \u0026#34;Invalid customer location\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } The implementation of CustomerLocationValidator would override the isValid() method and check if the input is valid or not.\npublic class CustomerLocationValidator implements ConstraintValidator\u0026lt;ValidCustomerLocation, CustomerLocation\u0026gt; { @Autowired Validator validator; @Override public boolean isValid(CustomerLocation customerLocation, ConstraintValidatorContext constraintValidatorContext) { boolean isValid = true; Set\u0026lt;ConstraintViolation\u0026lt;CustomerLocation\u0026gt;\u0026gt; constraintViolations = new HashSet(); constraintViolations = validator.validate(customerLocation); if (!CollectionUtils.isEmpty(constraintViolations)) { constraintValidatorContext.disableDefaultConstraintViolation(); for (ConstraintViolation\u0026lt;CustomerLocation\u0026gt; violation : constraintViolations) { constraintValidatorContext .buildConstraintViolationWithTemplate(violation.getMessageTemplate()) .addConstraintViolation(); } isValid = false; } return isValid; } } Attributes with @NumericString annotation would be validated by NumericStringValidator class as shown below:\n@Target({ElementType.FIELD, ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Constraint(validatedBy = {NumericStringValidator.class}) @Documented public @interface NumericString { String message() default \u0026#34;String should be numeric\u0026#34;; Class\u0026lt;?\u0026gt;[] groups() default {}; Class\u0026lt;? extends Payload\u0026gt;[] payload() default {}; } The implementation of NumericStringValidator would override the isValid() method and check if the attributes annotated with @NumericString contains only numerals using the regular expression check:\npublic class NumericStringValidator implements ConstraintValidator\u0026lt;NumericString, String\u0026gt; { @Override public boolean isValid(String str, ConstraintValidatorContext constraintValidatorContext) { if (str.matches(\u0026#34;[0-9]+\u0026#34;)) return true; return false; } } Time to test: Complete code base is present at the below git location:\nhttps://github.com/rohanmukesh/spring-boot-custom-validator.git\nClone the codebase, build and run the CustomvalidatorApplication class. The application runs on default port 8080. Once it is up and running perform the below two tests:\n1. Valid request: Endpoint URL: localhost:8080/v1/validate\n{ \u0026#34;locationId\u0026#34;:\u0026#34;123\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Frisco\u0026#34;, \u0026#34;countryCode\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;postCode\u0026#34;:\u0026#34;000000\u0026#34; } Response:\nStatus: HTTP response code 202 Accepted\n2. Invalid request: Endpoint URL: localhost:8080/v1/validate\n{ \u0026#34;locationId\u0026#34;:\u0026#34;locationId\u0026#34;, \u0026#34;countryCode\u0026#34;:\u0026#34;countryCode\u0026#34;, \u0026#34;postCode\u0026#34;:\u0026#34;postCode\u0026#34; } Response: Status: HTTP response code 400 Bad Request\n{ \u0026#34;errorCode\u0026#34;: \u0026#34;400 BAD_REQUEST\u0026#34;, \u0026#34;errorMessage\u0026#34;: \u0026#34;Validation Errors\u0026#34;, \u0026#34;subErrors\u0026#34;: [ { \u0026#34;object\u0026#34;: \u0026#34;customerLocation\u0026#34;, \u0026#34;field\u0026#34;: \u0026#34;city\u0026#34;, \u0026#34;rejectedValue\u0026#34;: \u0026#34;city\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;city cannot not be empty\u0026#34; }, { \u0026#34;object\u0026#34;: \u0026#34;customerLocation\u0026#34;, \u0026#34;field\u0026#34;: \u0026#34;countryCode\u0026#34;, \u0026#34;rejectedValue\u0026#34;: \u0026#34;countryCode\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;countryCode should be numeric\u0026#34; }, { \u0026#34;object\u0026#34;: \u0026#34;customerLocation\u0026#34;, \u0026#34;field\u0026#34;: \u0026#34;postCode\u0026#34;, \u0026#34;rejectedValue\u0026#34;: \u0026#34;postCode\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;postCode should be numeric\u0026#34; }, { \u0026#34;object\u0026#34;: \u0026#34;customerLocation\u0026#34;, \u0026#34;field\u0026#34;: \u0026#34;locationId\u0026#34;, \u0026#34;rejectedValue\u0026#34;: \u0026#34;locationId\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;locationId should be numeric\u0026#34; } ] } "},{"uri":"/common/","title":"Let&#39;s get started","tags":["start"],"description":"","content":"Context Let\u0026rsquo;s start developing a modern cloud ready microservice using the greenfield-app-starter.\nThe starter allows you to develop a spring boot microservice based on Non-Reactive or Reactive paradigms.\nMoving a legacy monolith application to a microservice, we normally use the Non-Reactive framework, while a greenfield microservice is recommended to use the Reactive to take advantage of the non-blocking behavior provided by the framework.\nNext Step Follow the Reactive or Non-Reactive recipes depending on your business performance and resiliency needs.\nNotes and References  What is Reactive Programming ?  "},{"uri":"/best-practices/spring-boot-structure/","title":"Structuring Spring Boot","tags":["practices","spring boot","microservice","application development"],"description":"A simple guide to organizing Spring Boot apps","content":"Context This guide presents one possible way to structure a spring boot app. It is only a starting point for deciding a structure which best suits your team, requirements, company, time, and app complexity.\nLayers Why even have layers today? What year is this? \u0026ldquo;Most of the examples I see have one Spring bean which does config \u0026amp; endpoints \u0026amp; data \u0026amp; security \u0026amp; validation \u0026amp; pancakes.\u0026quot;\nAn argument can be made that trivial services (especially focused examples) have no need for the overhead of multiple layers, packages, separation of duties, abstraction, and even basic organization.\nAfter all, we aren\u0026rsquo;t building monoliths anymore, we\u0026rsquo;re building microsevices right?\nYes, but we are looking for a balance here between overhead and chaos.\nWe know at least the following:\n We need just enough abstraction for things to change easily (layers \u0026amp; interfaces) Other developers have to make sense of our code (convention \u0026amp; organization) Our code has to be easily testable (isolation \u0026amp; separation of duties).   Another big one: Annotation based frameworks commonly utilize dynamic proxies which only works on public method calls to spring-injected beans (i.e. hystrix, JPA, transactions etc.)\n \u0026ldquo;But even the Spring Initializr only gives me dependencies, and a single Application class\u0026rdquo;\nThe rest is left to you simply because there are so many options.\nStill here? Let\u0026rsquo;s look at one possible strategy.\nAPI Based Services Most http/api Spring Boot applications consist of 3 primary layer types.\n Controller (API Front End - Integration with external consumers) | v Services (POJO Capabilities i.e. the valuable stuff) | v Integration (Integration with external producers) Integration classes are injected into services, services are injected into controllers or other services for composition.\nCalls through layers go down, never up (no integration classes calling Services).\nController Layer This is the API exposure layer. It accepts and returns http request/response and defines how external clients will interact with the service.\nYou can organize parts of the API into separate controller classes, though sometimes this is an indication that the service should be split into smaller microservices.\nThis should be the only layer that \u0026ldquo;knows\u0026rdquo; it is a webservice at all (don\u0026rsquo;t pass raw http request/response through service layer).\n IMPORTANT: Do not make database calls or calls to other services in the controller.\nAs much as possible, place only http related mapping/translating/versioning code here (and potentially authorization code depending on your design).\n It is simply a http adapter to the capabilities of your service.\nThe controller layer has the final exception handling responsibilities as well: Controller Advice\nService Layer This layer contains one or more classes representing the internal composable capabilities of the app.\nThe name \u0026ldquo;service\u0026rdquo; used here can sometimes confuse developers new to Spring vernacular. It refers to classes which are the composable, plain Java, \u0026ldquo;middle bit\u0026rdquo; of the application which do not deal with protocols or other integration concerns.\nServices should contain things like business logic, data transformation, user authorization and calls to the DAOs.\nServices can aggregate/compose/orchestrate across other services\nIntegration Layer Contains one or more classes which perform integrations with other webservices, databases, message queues, etc.\nCommon naming conventions for integration classes depending on their purpose:\n DAO (A bit too generic, but widely used) Repository (Mostly CRUD data operations) Sender (Message sender over Kafka, JMS, AMQP etc.)   UNIMPORTANT: For an integration which is more than just data operations (think tax calculation), some folks use a different suffix such as \u0026ldquo;Engine\u0026rdquo;.\n Example:\n AccountController | AccountService / \\ AccountDataService CustomerService / \\ *AccountRepo* *CustomerRepo* Integration classes should follow an interface/implementation pattern.\nAccountRepo  would be the interface, JDBCAccountRepo would be a potential implementation of the interface (I know naming things is hard, Please don\u0026rsquo;t call it an \u0026ldquo;Impl\u0026rdquo;)\nMessage Services Message services are structured nearly the same as an API service, but instead of a controller they have a message listener.\nExample:\n AccountMessageListener | AccountService | AccountRepo Non-layer Classes Models Contains plain java classes which represent data passed between the layers of an application.\nEach layer may have its own models depending on the abstraction needed (one model or \u0026ldquo;translate everywhere\u0026rdquo;).\nMany difficult trade-offs are made here between simplicity and abstraction.\nApplication A single class which declares your app as Spring Boot-able.\nConfig Any spring bean config which is not embedded in the bean itself (annotations) will go here. This is usually limited to security config and declaration of spring beans that you did not write.\nInput Validation Where to do input validation for attribute x is often a subject of debate.\nSince there is no one right answer for all input types, we\u0026rsquo;ll just list some things to consider when making the decision.\nWherever you choose to validate, it\u0026rsquo;s usually best to move this to its own class.\nConsiderations:\n Some input validation (format or required elements) can change depending on the API version of the service Input validation error responses should include the attribute value and location which caused the error (if safe to do so) Some input validation is consistent across API versions and duplication of code may not be desirable If you use Spring Bean Validation, you have less code to write but also less control over where/when things happen  API Versioning  NOTE: This section is not meant to be a full API versioning strategy (that\u0026rsquo;s a different recipe). It should only recommend where to implement a versioning strategy within the layers described above. If it accidentally oversteps, refer to the main versioning recipe.\n API major-versioning should be done as a last resort because it adds a hefty maintenance cost. Favor backward compatible API changes when possible.\nIf you choose to maintain multiple major versions of an API (within the same app) this versioning should be done in the controller. Any data translation which is version specific should be done here.\nEach major version should be represented by a separate controller class\nExample: AccountControllerV1 \u0026amp; AccountControllerV2\nTo illustrate, consider the account-service which supports 3 versions concurrently: Option #1 - Chaining Translation\n AccountControllerV1 -\u0026gt; AccountControllerV2 -\u0026gt; AccountControllerV3 | AccountService | AccountRepo Option #2 - Direct Translation\n AccountControllerV1 AccountControllerV2 AccountControllerV3 \\ | / AccountService | AccountRepo The AccountService (business logic and orchestration) does not know anything about versioning. It implicitly represents the highest version.\nThe highest version controller (AccountControllerV3) does not do any versioning, it just calls the AccountService .\nLower version controllers either translate up in a chain (v1-\u0026gt;v2-\u0026gt;v3) or translate and directly call the AccountService  (v1-\u0026gt;v3).\nDoes this mean I have a different set of API models for each controller/version? If the major version change is non-trivial and involves structural changes to the API model classes, yes. Another reason to avoid this.\nPackage Organization Again, there are many ways to do this just keep in mind that consistency across projects makes it easier for new developers (though keeping services extremely small makes this slightly less important).\nHorizontal or vertical? Package by layer or package by feature? https://dzone.com/articles/project-package-organization\nPackage by Layer Example com.wellsfargo.cto.eai/ TrackingApplication.java com.wellsfargo.cto.eai.config/ SecurityConfig.java RedisConfig.java com.wellsfargo.cto.eai.controller/ AccountController.java AccountControllerAdvice.java AccountInputValidator.java com.wellsfargo.cto.eai.controller.model/ AccountRequest.java AccountResponse.java ... com.wellsfargo.cto.eai.model/ AccountStatus.java Customer.java ... com.wellsfargo.cto.eai.service/ AccountService.java CustomerService.java com.wellsfargo.cto.eai.repo/ AccountRepo.java JDBCAcountRepo.java CustomerRepo.java CDSCustomerRepo.java com.wellsfargo.cto.eai.repo.model/ Customer.java\tPackage by Feature Example \t"},{"uri":"/recipes-non-reactive/","title":"Non-Reactive Recipes","tags":[],"description":"","content":"Cookbook with recipes for developing modern cloud native application created by VMWare Pivotal Labs engagement during the Enterprise Architecture Consulting engagement.\n"},{"uri":"/recipes-reactive/","title":"Reactive Recipes","tags":[],"description":"","content":"REACTIVE Recipes Cookbook with recipes for developing modern cloud native application created by VMWare Pivotal Labs engagement during the Enterprise Architecture Consulting engagement.\n"},{"uri":"/best-practices/","title":"Best Practices","tags":["practices"],"description":"","content":"Context Best practices for developing a modern cloud ready microservice using the greenfield-app-starter.\nNotes and References "},{"uri":"/tags/anti-patterns/","title":"anti patterns","tags":[],"description":"","content":""},{"uri":"/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"/recipes-non-reactive/configure-redis-cache/","title":"Configure Redis","tags":["starter","spring-boot-app","microservice"],"description":"","content":"Context This is the third recipe in the series, for developing a modern cloud ready microservice using the greenfield-app-starter.\nThis recipe deals with configuring the microservice to use a distributed (Redis) cache for data caching needs.\nPrerequisite  STEP 1: CREATE APPLICATION USING STARTER is completed.  Solution   Determine and record the following redis cache connection details\n   Property Details     jdbc url jdbc:oracle:thin:@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;:\u0026lt;schema\u0026gt; [thin] OR jdbc:oracle:oci:@\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;:\u0026lt;schema\u0026gt; [oci]   driver classname oracle.jdbc.OracleDriver   schema database schema name   dialect Hibernate dialect based on the Oracle database version org.hibernate.dialect.Oracle12cDialect   username schema username   password schema password      Determine and record the cache connection pool requirements for the new microservice\n   Property Suggested Values     maximumPoolSize 10   idlePoolSize 2   connectionTimeout 250ms   idleTimeout 800ms   maxLifetime 3000ms      Navigate to the \u0026lt;microservice\u0026gt; directory\n  Update src/main/resources/application.yml with Redis (connection, credentials and connection pool) details.\napplication:name:description:id:\u0026lt;wells fargo distributed-id\u0026gt;persistence:..........cache:redis:name:\u0026lt;redis server name\u0026gt; host:\u0026lt;hostname or ip address of the redis cache\u0026gt;port:username:password:timeout:\u0026lt;in ms\u0026gt;time-to-live:\u0026lt;in minutes\u0026gt;enable-repository:\u0026lt;true or false\u0026gt;connection-pool:max-active:max-idle:max-wait:\u0026lt;in ms\u0026gt;min-idle:cluster-nodes:\u0026lt;comma seperated host:port pairs\u0026gt;sentinel-nodes:\u0026lt;comma seperated host:port pairs\u0026gt;  Validation   Open a command window in the \u0026lt;microservice-name\u0026gt; directory\n  Validate the new microservice can be built locally: gradlew bootJar\n  Validate the new microservice runs locally: gradlew bootRun\n  Verify microservice health and info in the browser\n  http://localhost:8080/actuator/info\n  http://localhost:8080/actuator/health\nthe redis cache details and uptime status should be displayed in the browser.\n    How to enable caching in your application ?   add @EnableCaching to one of your configuration classes. (preferably the class annotated with @SpringBootApplication)\n  add @Cacheable to the methods you want to enable caching.\n  optionally, add @CacheEvict to remove/delete the cached object.\n  Here is a example that demonstrates the annotations in a typical service.\n@Service public class ItemService { private final ItemRepository itemRepository; public ItemService(ItemRepository itemRepository) { this.itemRepository = itemRepository; } public List\u0026lt;Item\u0026gt; items() { return itemRepository.findAll(); } @Cacheable(value = \u0026#34;items\u0026#34;, key = \u0026#34;#id\u0026#34;) public Item getItem(Integer id) { Item item = itemRepository.findById(id); return item; } public Item createItem(Item item) { return itemRepository.save(item); } @CacheEvict(value = \u0026#34;items\u0026#34;, key = \u0026#34;#id\u0026#34;) public Item updateItem(Integer id, Item request) { Item item = getItem(id); item.setPrice(request.getPrice()); item.setProductName(request.getProductName()); return itemRepository.save(item); } } Next Step Configure the Messaging\nNotes and References Recommendations   Cacheable objects must be Serializable\nThe reason is due to how redis stores java objects. The safest way to store objects outside JVM is to write them into serialized bytes. To do that, those classes must implement Serializable.\n  Set the TTL\nTake advantage of expiring keys and Redis will clean up for you\n  Choosing the Proper Eviction Policy\nWhen your Redis instance fills up, Redis will attempt to evict keys. Depending on your use case, we recommend volatile-lru assuming you have expiring keys. If you’re running like a cache and don’t have an expiry set, you could consider allkeys-lru.\n  Try not to cache large objects.\nLarge objects in the cache will cause performance issues.\n  Make sure all applications using the same cache are at the same version.\nCached objects created by application with the version A may not be compatible to the application with the version B. These type of situations will yield unpredictable results.\n  "},{"uri":"/tags/database-connection-pool/","title":"database connection pool","tags":[],"description":"","content":""},{"uri":"/tags/hikari/","title":"hikari","tags":[],"description":"","content":""},{"uri":"/tags/microservice/","title":"microservice","tags":[],"description":"","content":""},{"uri":"/tags/persistence/","title":"persistence","tags":[],"description":"","content":""},{"uri":"/categories/recipes/","title":"recipes","tags":[],"description":"","content":""},{"uri":"/tags/spring-boot-app/","title":"spring-boot-app","tags":[],"description":"","content":""},{"uri":"/tags/starter/","title":"starter","tags":[],"description":"","content":""},{"uri":"/tags/","title":"Tags","tags":[],"description":"","content":""},{"uri":"/tags/application-development/","title":"application development","tags":[],"description":"","content":""},{"uri":"/tags/barebone-microservice/","title":"barebone microservice","tags":[],"description":"","content":""},{"uri":"/tags/custom-spring-bean-validation/","title":"custom spring bean validation","tags":[],"description":"","content":""},{"uri":"/tags/practices/","title":"practices","tags":[],"description":"","content":""},{"uri":"/tags/spring-boot/","title":"spring boot","tags":[],"description":"","content":""},{"uri":"/tags/start/","title":"start","tags":[],"description":"","content":""},{"uri":"/","title":"Home","tags":[],"description":"Cookbook Home Page","content":"Greenfield Microservice Starter Cookbook with recipes for developing modern cloud native microservice created by VMWare Pivotal Labs during the WellsFargo Enterprise Architecture Consulting engagement.\n"},{"uri":"/_header/","title":"","tags":[],"description":"","content":"  Application Starter Cookbook\n"}]